---
title: "Foolbox Native: Fast adversarial attacks to benchmark the robustness of machine learning models in PyTorch, TensorFlow, and JAX"
type: paper
collection: publications
permalink: /publication/2020-11-01-contrastive-disentanglement
excerpt: 'Foolbox is a popular Python library to benchmark the robustness of machine learning models against these adversarial perturbations'
date: 2020-09-27
paperurl: 'https://joss.theoj.org/papers/10.21105/joss.02607.pdf'
paperurldescription: 'Access the workshop paper'
authors: 'Jonas, R., **Zimmermann, R. S.**, Bethge, M. and Brendel, W.,'
venue: 'Journal of Open Source Software'
citation: 'Jonas, R. Zimmermann, R. S., Bethge, M. and Brendel, W., Foolbox Native: Fast adversarial attacks to benchmark the robustness of machine learning models in PyTorch, TensorFlow, and JAX.'
---
Machine learning has made enormous progress in recent years and is now being used in many real-world applications. Nevertheless, even state-of-the-art machine learning models can be fooled by small, maliciously crafted perturbations of their input data. Foolbox is a popular Python library to benchmark the robustness of machine learning models against these adversarial perturbations. It comes with a huge collection of state-of-the-art adversarial attacks to find adversarial perturbations and thanks to its framework-agnostic design it is ideally suited for comparing the robustness of many different models implemented in different frameworks. Foolbox 3 aka Foolbox Native has been rewritten from scratch to achieve native performance on models developed in PyTorch (Paszke et al., 2019), TensorFlow (Abadi et al., 2016), and JAX (Bradbury et al., 2018), all with one codebase without code duplication.

[Download paper here](https://joss.theoj.org/papers/10.21105/joss.02607.pdf)